import cv2
import numpy as np
import yaml
import os
from typing import Dict, Any
from scipy.spatial.transform import Rotation as R


class ArucoDetector:
    def __init__(self, config_path: str):
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")

        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

        self.marker_length = float(self.config.get('marker_length', 0.05))
        aruco_dict_name = self.config.get('aruco_dict', 'DICT_5X5_50')
        self.camera_id = int(self.config.get('camera_id', 0))

        if not hasattr(cv2.aruco, aruco_dict_name):
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å ArUco: {aruco_dict_name}")
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(getattr(cv2.aruco, aruco_dict_name))

        self.detector_params = cv2.aruco.DetectorParameters()
        det_params_config = self.config.get('detector_params', {})
        for param_name, value in det_params_config.items():
            if hasattr(self.detector_params, param_name):
                setattr(self.detector_params, param_name, value)
            else:
                print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞: '{param_name}'")

        # üîç –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å –∫ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ, —á—Ç–æ –∏ config.yaml
        config_dir = os.path.dirname(os.path.abspath(config_path))
        calibration_file = os.path.join(config_dir, "camera_calibration_good.npz")

        if not os.path.exists(calibration_file):
            raise FileNotFoundError(f"–§–∞–π–ª –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {calibration_file}")

        with np.load(calibration_file) as data:  # ‚Üê –í–ê–ñ–ù–û: 'data' –ø–æ—Å–ª–µ 'as'
            self.camera_matrix = data['camera_matrix'].astype(np.float32)
            self.dist_coeffs = data['dist_coeffs'].astype(np.float32)
            if self.dist_coeffs.ndim == 2:
                self.dist_coeffs = self.dist_coeffs.flatten()

        self.detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.detector_params)

        half = self.marker_length / 2
        self.marker_obj_points = np.array([
            [-half,  half, 0],
            [ half,  half, 0],
            [ half, -half, 0],
            [-half, -half, 0]
        ], dtype=np.float32)

        self.last_pose: Dict[int, Dict[str, Any]] = {}

    def detect(self, image: np.ndarray):
        if image is None or image.size == 0:
            return [], None
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        corners, ids, _ = self.detector.detectMarkers(gray)
        return corners, ids

    def estimate_pose(self, corners, ids):
        if ids is None or len(ids) == 0 or len(corners) != len(ids):
            return [], []

        rvecs, tvecs = [], []
        for corner in corners:
            img_points = corner.reshape((4, 2))
            success, rvec, tvec = cv2.solvePnP(
                self.marker_obj_points,
                img_points,
                self.camera_matrix,
                self.dist_coeffs,
                flags=cv2.SOLVEPNP_IPPE_SQUARE
            )
            if success:
                rvecs.append(rvec)
                tvecs.append(tvec)
            else:
                rvecs.append(np.zeros((3, 1), dtype=np.float32))
                tvecs.append(np.zeros((3, 1), dtype=np.float32))
        return rvecs, tvecs

    def get_pos(self, image: np.ndarray) -> Dict[int, Dict[str, Any]]:
        corners, ids = self.detect(image)
        rvecs, tvecs = self.estimate_pose(corners, ids)

        if ids is not None:
            for i, mid in enumerate(ids.flatten()):
                marker_id = int(mid)
                rvec = rvecs[i].copy()
                tvec = tvecs[i].copy()
                rmat, _ = cv2.Rodrigues(rvec)
                rot = R.from_matrix(rmat)
                euler = rot.as_euler('xyz', degrees=True)

                self.last_pose[marker_id] = {
                    'position': tvec.flatten(),
                    'distance': float(np.linalg.norm(tvec)),
                    'euler_angles': euler.tolist(),
                    'rotation_vector': rvec.flatten().tolist(),
                    'valid': True
                }

        detected_ids = set(ids.flatten()) if ids is not None else set()
        for mid in self.last_pose:
            if mid not in detected_ids:
                self.last_pose[mid]['valid'] = False

        return self.last_pose.copy()

    def draw(self, image: np.ndarray) -> np.ndarray:
        corners, ids = self.detect(image)
        rvecs, tvecs = self.estimate_pose(corners, ids)
        output = image.copy()

        if ids is not None:
            cv2.aruco.drawDetectedMarkers(output, corners, ids)
            for i, marker_id in enumerate(ids.flatten()):
                pts = corners[i].reshape((4, 2))
                cx = int(np.mean(pts[:, 0]))
                cy = int(np.mean(pts[:, 1]))

                pose = self.last_pose.get(int(marker_id))
                if not pose:
                    continue

                dist = pose['distance']
                euler = pose['euler_angles']
                label = f"ID{marker_id}\nD={dist:.2f}m\nR={euler[0]:.0f}¬∞ P={euler[1]:.0f}¬∞ Y={euler[2]:.0f}¬∞"
                y0 = cy - 60
                for j, line in enumerate(label.split('\n')):
                    cv2.putText(output, line, (cx - 30, y0 + j * 20),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)
        return output


# =============================
# –û–°–ù–û–í–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê
# =============================
if __name__ == "__main__":
    CONFIG_PATH = r"C:\Users\student\Desktop\artHzBan\config.yaml"

    try:
        detector = ArucoDetector(CONFIG_PATH)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        exit(1)

    print(f"üì∑ –ü–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ –∫–∞–º–µ—Ä–µ {detector.camera_id}...")
    cap = cv2.VideoCapture(detector.camera_id)

    if not cap.isOpened():
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É {detector.camera_id}")
        exit(1)

    print("‚úÖ –ó–∞–ø—É—â–µ–Ω–æ. –ù–∞–∂–º–∏—Ç–µ ESC –¥–ª—è –≤—ã—Ö–æ–¥–∞.")
    frame_count = 0
    UPDATE_INTERVAL = 10  # –æ–±–Ω–æ–≤–ª—è—Ç—å –∫–æ–Ω—Å–æ–ª—å –∫–∞–∂–¥—ã–µ 10 –∫–∞–¥—Ä–æ–≤

    # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    last_known_ids = set()

    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
            break

        all_poses = detector.get_pos(frame)
        output_frame = detector.draw(frame)

        # --- –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Å–æ–ª—å —Ä–∞–∑ –≤ N –∫–∞–¥—Ä–æ–≤ ---
        frame_count += 1
        if frame_count % UPDATE_INTERVAL == 0:
            current_ids = set(all_poses.keys())
            if current_ids != last_known_ids:
                # –í—ã–≤–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä–∞ ID
                print("\n" + "="*50)
                print("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º–∞—Ä–∫–µ—Ä—ã:" if current_ids else "–ù–µ—Ç –º–∞—Ä–∫–µ—Ä–æ–≤")
                last_known_ids = current_ids

            if all_poses:
                for mid, data in all_poses.items():
                    status = "–í–∏–¥–µ–Ω" if data['valid'] else "–ü–æ—Ç–µ—Ä—è–Ω (–∫—ç—à)"
                    pos = data['position']
                    e = data['euler_angles']
                    dist = data['distance']
                    print(f"\n[ID {mid}] {status}")
                    print(f"  –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {dist:.3f} –º")
                    print(f"  –£–≥–ª—ã (Roll, Pitch, Yaw): [{e[0]:.1f}, {e[1]:.1f}, {e[2]:.1f}]¬∞")
                    print(f"  –ü–æ–∑–∏—Ü–∏—è (X, Y, Z): [{pos[0]:.3f}, {pos[1]:.3f}, {pos[2]:.3f}]")
            else:
                print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –º–∞—Ä–∫–µ—Ä–∞—Ö")

        # --- –ü–æ–∫–∞–∑ –≤–∏–¥–µ–æ ---
        cv2.imshow("Aruco Tracker", output_frame)

        if cv2.waitKey(1) == 27:  # ESC
            break

    cap.release()
    cv2.destroyAllWindows()
    print("\n‚èπÔ∏è  –ó–∞–≤–µ—Ä—à–µ–Ω–æ")
